{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2ee25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder_path, image_size=(224, 224), validation_split=0):\n",
    "   \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all subfolders (classes)\n",
    "    class_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    \n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        print(f\"Loading images from class: {class_name}\")\n",
    "        \n",
    "        # Get all images in the class folder\n",
    "        for image_name in os.listdir(class_path):\n",
    "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                \n",
    "                # Read and preprocess the image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    # Convert BGR to RGB\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    # Resize image\n",
    "                    image = cv2.resize(image, image_size)\n",
    "                    # Normalize pixel values to [0, 1]\n",
    "                    image = image / 255.0\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    labels.append(class_name)\n",
    "                    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    if validation_split > 0:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            images, labels, \n",
    "            test_size=validation_split,\n",
    "            random_state=42,\n",
    "            stratify=labels  # Ensure balanced split across classes\n",
    "        )\n",
    "        return X_train, X_val, y_train, y_val\n",
    "    else:\n",
    "        return images, labels\n",
    "\n",
    " # Load training data\n",
    "train_path = \"BrainTumourDetection-AISE3000/train\"\n",
    "X_train, y_train= load_images_from_folder(train_path)\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Number of training labels: {len(y_train)}\")\n",
    "\n",
    "#Data is initially split into 80% train and 20% test so splitting the test set gives an 80/10/10 train/val/test split\n",
    "# Load testing data and split into test and validation sets\n",
    "test_path = \"BrainTumourDetection-AISE3000/test\"\n",
    "X_test, X_val, y_test, y_val = load_images_from_folder(test_path, validation_split=0.5)\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(f\"Number of testing labels: {len(y_test)}\")   \n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Number of validation labels: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_samples(images, labels, num_samples_per_class=5):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each class in a grid\n",
    "    \"\"\"\n",
    "    # Get unique classes\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(num_classes, num_samples_per_class, \n",
    "                            figsize=(15, 3*num_classes))\n",
    "    fig.suptitle('Sample Images from Each Class', fontsize=16)\n",
    "    \n",
    "    # Plot samples from each class\n",
    "    for i, class_name in enumerate(unique_classes):\n",
    "        # Get indices for current class\n",
    "        class_indices = np.where(labels == class_name)[0]\n",
    "        \n",
    "        # Randomly select samples\n",
    "        selected_indices = np.random.choice(class_indices, \n",
    "                                          min(num_samples_per_class, len(class_indices)), \n",
    "                                          replace=False)\n",
    "        \n",
    "        # Plot each sample\n",
    "        for j, idx in enumerate(selected_indices):\n",
    "            axes[i, j].imshow(images[idx])\n",
    "            axes[i, j].axis('off')\n",
    "            if j == 0:  # Only show class name on first image of each row\n",
    "                axes[i, j].set_title(class_name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nVisualizing training samples:\")\n",
    "visualize_samples(X_train, y_train)\n",
    "print(\"\\nVisualizing validation samples:\")\n",
    "visualize_samples(X_val, y_val)\n",
    "print(\"\\nVisualizing testing samples:\")\n",
    "visualize_samples(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
